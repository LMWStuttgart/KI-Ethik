## Black Box
Eine Black Box ist ein System, dessen interne Mechanismen nicht nachvollzogen werden können. Im Feld des Maschinellen Lernens bezieht sich Black Box auf ein Modell, das anhand seiner Parameter nicht verstanden werden kann: Daten werden eingegeben und führen zu bestimmten Entscheidungen, aber der Prozess zwischen Ein- und Ausgabe ist nicht transparent. Insbesondere bei Modellen, die neuronale Netze imitieren, durchlaufen die Eingabedaten zahlreiche Veränderungen oder verhalten sich auf unvorhersehbare Weise. In einer beispielhaften Umsetzung kann der Einsatz von KI dazu führen, dass Einzelpersonen aufgrund nicht weiter erklärbarer Entscheidungen des Algorithmus höhere Versicherungsprämien angeboten oder Hypotheken verweigert werden. In den letzten Jahren wurden verstärkt Anstrengungen unternommen, um besser interpretierbare Modelle des Maschinellen Lernens zu entwickeln, so dass die Algorithmen eine gewisse Begründung oder Erklärung für ihre Entscheidungen mitliefern.
</br></br>
Hinweis: Der Text referenziert einen Begriff in den [Leitlinien für den Einsatz von KI im Landesmuseum Württemberg](01_Leitlinien.md)
