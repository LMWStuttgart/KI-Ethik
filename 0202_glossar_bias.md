## Bias
Bias (“Voreingenommenheit”) in Künstlicher Intelligenz entsteht durch ungleichmäßig repräsentierte oder fehlerhafte Datensätze, die Vorurteile und Diskriminierung gegenüber bestimmten Gruppen oder Merkmalen verstärken können. Biases kann zu ungerechten Entscheidungen führen und bestehende gesellschaftliche Ungleichheiten verstärken. Um diese Problematik anzugehen, ist es wichtig, Biases in den Datensätzen zu erkennen, zu quantifizieren und zu mindern, um faire und ethisch vertretbare KI-Systeme zu entwickeln.
Hilfreiches Wissen zu Bias: https://www.anti-bias.eu/wissen/biases-von-a-z/
</br></br>
Hinweis: Der Text referenziert einen Begriff in den [Leitlinien für den Einsatz von KI im Landesmuseum Württemberg](01_Leitlinien.md)
